# Day 3: çŸ©é˜µä¹˜æ³•ä¼˜åŒ– - CUDAæ€§èƒ½è°ƒä¼˜å®æˆ˜

## æ¦‚è¿°
ä»Šå¤©æˆ‘ä»¬å°†å­¦ä¹ çŸ©é˜µä¹˜æ³•ï¼Œè¿™æ˜¯æ·±åº¦å­¦ä¹ ä¸­çš„æ ¸å¿ƒæ“ä½œã€‚æˆ‘ä»¬å°†ä»ç®€å•çš„å®ç°å¼€å§‹ï¼Œé€æ­¥ä¼˜åŒ–åˆ°é«˜æ€§èƒ½ç‰ˆæœ¬ï¼Œå­¦ä¹ å„ç§CUDAä¼˜åŒ–æŠ€æœ¯ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬è¿˜å°†äº†è§£NVIDIAæä¾›çš„å®˜æ–¹ä¼˜åŒ–åº“ï¼Œå¦‚cuBLASå’ŒCUTLASSï¼Œè¿™äº›åº“å·²ç»å®ç°äº†é«˜åº¦ä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•ç®—æ³•ã€‚

## å­¦ä¹ ç›®æ ‡
- ç†è§£çŸ©é˜µä¹˜æ³•çš„ç®—æ³•å’Œå®ç°
- æŒæ¡CUDAå…±äº«å†…å­˜çš„ä½¿ç”¨
- å­¦ä¼šä½¿ç”¨CUDAæµè¿›è¡Œå¼‚æ­¥æ“ä½œ
- ç†è§£å†…å­˜åˆå¹¶è®¿é—®çš„é‡è¦æ€§
- æŒæ¡æ€§èƒ½åˆ†æå’Œè°ƒä¼˜æŠ€å·§
- äº†è§£NVIDIAå®˜æ–¹ä¼˜åŒ–åº“çš„ä½¿ç”¨

## çŸ©é˜µä¹˜æ³•åŸºç¡€

### 1. æ•°å­¦å®šä¹‰
å¯¹äºçŸ©é˜µ A (MÃ—K) å’Œ B (KÃ—N)ï¼Œç»“æœçŸ©é˜µ C (MÃ—N) çš„è®¡ç®—ï¼š
```
C[i][j] = Î£(A[i][k] * B[k][j]) for k = 0 to K-1
```

### 2. è®¡ç®—å¤æ‚åº¦
- æ—¶é—´å¤æ‚åº¦ï¼šO(MÃ—NÃ—K)
- ç©ºé—´å¤æ‚åº¦ï¼šO(MÃ—N + MÃ—K + KÃ—N)
- å†…å­˜è®¿é—®æ¨¡å¼å¯¹æ€§èƒ½å½±å“å·¨å¤§

## NVIDIAå®˜æ–¹ä¼˜åŒ–åº“

### 1. cuBLAS (CUDA Basic Linear Algebra Subroutines)
cuBLASæ˜¯NVIDIAæä¾›çš„åŸºç¡€çº¿æ€§ä»£æ•°åº“ï¼ŒåŒ…å«é«˜åº¦ä¼˜åŒ–çš„çŸ©é˜µä¹˜æ³•å®ç°ï¼š

```cpp
#include <cublas_v2.h>

// ä½¿ç”¨cuBLASè¿›è¡ŒçŸ©é˜µä¹˜æ³•
void matrixMulCuBLAS(float *A, float *B, float *C, int M, int N, int K) {
    cublasHandle_t handle;
    cublasCreate(&handle);
    
    float alpha = 1.0f;
    float beta = 0.0f;
    
    // C = alpha * A * B + beta * C
    cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N,
                 M, N, K, &alpha, A, M, B, K, &beta, C, M);
    
    cublasDestroy(handle);
}

// æ‰¹å¤„ç†çŸ©é˜µä¹˜æ³•
void batchMatrixMulCuBLAS(float *A[], float *B[], float *C[], 
                          int M, int N, int K, int batchSize) {
    cublasHandle_t handle;
    cublasCreate(&handle);
    
    float alpha = 1.0f;
    float beta = 0.0f;
    
    // æ‰¹å¤„ç†çŸ©é˜µä¹˜æ³•
    cublasSgemmBatched(handle, CUBLAS_OP_N, CUBLAS_OP_N,
                       M, N, K, &alpha, A, M, B, K, &beta, C, M, batchSize);
    
    cublasDestroy(handle);
}
```

**cuBLASä¼˜åŠ¿:**
- é’ˆå¯¹ä¸åŒGPUæ¶æ„é«˜åº¦ä¼˜åŒ–
- æ”¯æŒå¤šç§æ•°æ®ç±»å‹å’Œç²¾åº¦
- è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç®—æ³•
- ç»è¿‡å……åˆ†æµ‹è¯•å’ŒéªŒè¯

### 2. CUTLASS (CUDA Templates for Linear Algebra Subroutines)
CUTLASSæ˜¯NVIDIAæä¾›çš„æ¨¡æ¿åŒ–çº¿æ€§ä»£æ•°åº“ï¼Œå…è®¸å¼€å‘è€…è‡ªå®šä¹‰å’Œä¼˜åŒ–çŸ©é˜µä¹˜æ³•ç®—æ³•ï¼š

```cpp
#include <cutlass/gemm/device/gemm.h>
#include <cutlass/layout/matrix.h>

// ä½¿ç”¨CUTLASSè¿›è¡ŒçŸ©é˜µä¹˜æ³•
void matrixMulCUTLASS(float *A, float *B, float *C, int M, int N, int K) {
    using ElementOutput = float;
    using ElementAccumulator = float;
    using ElementCompute = float;
    
    using LayoutInputA = cutlass::layout::RowMajor;
    using LayoutInputB = cutlass::layout::ColumnMajor;
    using LayoutOutput = cutlass::layout::RowMajor;
    
    using Gemm = cutlass::gemm::device::Gemm<
        ElementOutput, LayoutInputA,
        ElementOutput, LayoutInputB,
        ElementOutput, LayoutOutput,
        ElementAccumulator,
        cutlass::arch::OpClassSimt,
        cutlass::arch::Sm70
    >;
    
    typename Gemm::Arguments arguments{
        {M, N, K},
        {A, M}, {B, K}, {C, M},
        {C, M},
        {ElementCompute(1), ElementCompute(0)}
    };
    
    Gemm gemm_op;
    gemm_op.initialize(arguments);
    gemm_op();
}
```

**CUTLASSç‰¹æ€§:**
- é«˜åº¦å¯å®šåˆ¶çš„ç®—æ³•å®ç°
- æ”¯æŒä¸åŒçš„æ•°æ®å¸ƒå±€å’Œç²¾åº¦
- é’ˆå¯¹ç‰¹å®šå·¥ä½œè´Ÿè½½ä¼˜åŒ–
- å¼€æºï¼Œå¯ä¿®æ”¹å’Œæ‰©å±•

### 3. æ€§èƒ½å¯¹æ¯”
```cpp
// æ€§èƒ½åŸºå‡†æµ‹è¯•
void benchmarkMatrixMultiplication(int M, int N, int K) {
    // åˆ†é…å†…å­˜
    float *A, *B, *C;
    cudaMalloc(&A, M * K * sizeof(float));
    cudaMalloc(&B, K * N * sizeof(float));
    cudaMalloc(&C, M * N * sizeof(float));
    
    // æµ‹è¯•è‡ªå®šä¹‰å®ç°
    auto start = std::chrono::high_resolution_clock::now();
    matrixMulCustom<<<grid, block>>>(A, B, C, M, N, K);
    cudaDeviceSynchronize();
    auto end = std::chrono::high_resolution_clock::now();
    auto custom_time = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    
    // æµ‹è¯•cuBLAS
    start = std::chrono::high_resolution_clock::now();
    matrixMulCuBLAS(A, B, C, M, N, K);
    cudaDeviceSynchronize();
    end = std::chrono::high_resolution_clock::now();
    auto cublas_time = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    
    // æµ‹è¯•CUTLASS
    start = std::chrono::high_resolution_clock::now();
    matrixMulCUTLASS(A, B, C, M, N, K);
    cudaDeviceSynchronize();
    end = std::chrono::high_resolution_clock::now();
    auto cutlass_time = std::chrono::duration_cast<std::chrono::microseconds>(end - start);
    
    printf("Custom: %ld Î¼s\n", custom_time.count());
    printf("cuBLAS: %ld Î¼s\n", cublas_time.count());
    printf("CUTLASS: %ld Î¼s\n", cutlass_time.count());
    
    cudaFree(A);
    cudaFree(B);
    cudaFree(C);
}
```

## å®ç°ç‰ˆæœ¬å¯¹æ¯”

### ç‰ˆæœ¬1: åŸºç¡€å®ç° (Global Memory)
```cpp
__global__ void matrixMulBasic(float *A, float *B, float *C, int M, int N, int K) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < M && col < N) {
        float sum = 0.0f;
        for (int k = 0; k < K; k++) {
            sum += A[row * K + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}
```

**é—®é¢˜åˆ†æ:**
- å…¨å±€å†…å­˜è®¿é—®ä¸åˆå¹¶
- æ¯ä¸ªçº¿ç¨‹éœ€è¦è®¿é—®Kä¸ªå…ƒç´ 
- å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ä½

### ç‰ˆæœ¬2: å…±äº«å†…å­˜ä¼˜åŒ–
```cpp
__global__ void matrixMulShared(float *A, float *B, float *C, int M, int N, int K) {
    __shared__ float sA[TILE_SIZE][TILE_SIZE];
    __shared__ float sB[TILE_SIZE][TILE_SIZE];
    
    int bx = blockIdx.x, by = blockIdx.y;
    int tx = threadIdx.x, ty = threadIdx.y;
    
    int row = by * TILE_SIZE + ty;
    int col = bx * TILE_SIZE + tx;
    
    float sum = 0.0f;
    
    for (int k = 0; k < K; k += TILE_SIZE) {
        // åä½œåŠ è½½æ•°æ®åˆ°å…±äº«å†…å­˜
        if (row < M && k + tx < K)
            sA[ty][tx] = A[row * K + k + tx];
        else
            sA[ty][tx] = 0.0f;
            
        if (col < N && k + ty < K)
            sB[ty][tx] = B[(k + ty) * N + col];
        else
            sB[ty][tx] = 0.0f;
            
        __syncthreads();
        
        // è®¡ç®—tileå†…çš„ç‚¹ç§¯
        for (int i = 0; i < TILE_SIZE; i++) {
            sum += sA[ty][i] * sB[i][tx];
        }
        __syncthreads();
    }
    
    if (row < M && col < N) {
        C[row * N + col] = sum;
    }
}
```

**ä¼˜åŒ–ç‚¹:**
- ä½¿ç”¨å…±äº«å†…å­˜å‡å°‘å…¨å±€å†…å­˜è®¿é—®
- æ•°æ®é‡ç”¨æé«˜å†…å­˜å¸¦å®½åˆ©ç”¨ç‡
- åä½œåŠ è½½æé«˜å†…å­˜åˆå¹¶è®¿é—®

### ç‰ˆæœ¬3: å¯„å­˜å™¨ä¼˜åŒ–
```cpp
__global__ void matrixMulRegisters(float *A, float *B, float *C, int M, int N, int K) {
    __shared__ float sA[TILE_SIZE][TILE_SIZE];
    __shared__ float sB[TILE_SIZE][TILE_SIZE];
    
    // ä½¿ç”¨å¯„å­˜å™¨å­˜å‚¨ä¸­é—´ç»“æœ
    float rA[TILE_SIZE];
    float rB[TILE_SIZE];
    float sum = 0.0f;
    
    // ... å®ç°ç»†èŠ‚
}
```

## æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯è¯¦è§£

### 1. å…±äº«å†…å­˜ä½¿ç”¨
- **ç›®çš„**: å‡å°‘å…¨å±€å†…å­˜è®¿é—®
- **ç­–ç•¥**: å°†é¢‘ç¹è®¿é—®çš„æ•°æ®ç¼“å­˜åˆ°å…±äº«å†…å­˜
- **æ³¨æ„äº‹é¡¹**: å…±äº«å†…å­˜å¤§å°é™åˆ¶ï¼Œéœ€è¦åˆ†å—å¤„ç†

### 2. å†…å­˜åˆå¹¶è®¿é—®
- **æ¦‚å¿µ**: ç›¸é‚»çº¿ç¨‹è®¿é—®ç›¸é‚»å†…å­˜åœ°å€
- **å®ç°**: åˆç†ç»„ç»‡çº¿ç¨‹ç´¢å¼•å’Œæ•°æ®å¸ƒå±€
- **æ•ˆæœ**: æé«˜å†…å­˜å¸¦å®½åˆ©ç”¨ç‡

### 3. çº¿ç¨‹å—å¤§å°ä¼˜åŒ–
- **è€ƒè™‘å› ç´ **: 
  - å…±äº«å†…å­˜ä½¿ç”¨é‡
  - å¯„å­˜å™¨ä½¿ç”¨é‡
  - warpå¤§å°(32)
- **æ¨èå€¼**: 16Ã—16, 32Ã—8, 8Ã—32ç­‰

### 4. å¾ªç¯å±•å¼€
- **ç›®çš„**: å‡å°‘å¾ªç¯å¼€é”€
- **å®ç°**: æ‰‹åŠ¨å±•å¼€å¾ªç¯æˆ–ä½¿ç”¨ç¼–è¯‘å™¨æŒ‡ä»¤
- **å¹³è¡¡**: ä»£ç å¤§å° vs æ€§èƒ½æå‡

## å¼‚æ­¥æ“ä½œå’ŒCUDAæµ

### 1. CUDAæµæ¦‚å¿µ
- æµæ˜¯GPUæ“ä½œçš„åºåˆ—
- åŒä¸€æµå†…æ“ä½œæŒ‰é¡ºåºæ‰§è¡Œ
- ä¸åŒæµå¯ä»¥å¹¶è¡Œæ‰§è¡Œ

### 2. å®ç°ç¤ºä¾‹
```cpp
cudaStream_t stream1, stream2;
cudaStreamCreate(&stream1);
cudaStreamCreate(&stream2);

// åœ¨æµ1ä¸­å¤„ç†çŸ©é˜µA
cudaMemcpyAsync(d_A1, h_A1, size, cudaMemcpyHostToDevice, stream1);
matrixMulKernel<<<grid, block, 0, stream1>>>(d_A1, d_B, d_C1, M, N, K);

// åœ¨æµ2ä¸­å¤„ç†çŸ©é˜µB
cudaMemcpyAsync(d_A2, h_A2, size, cudaMemcpyHostToDevice, stream2);
matrixMulKernel<<<grid, block, 0, stream2>>>(d_A2, d_B, d_C2, M, N, K);
```

### 3. é‡å è®¡ç®—å’Œä¼ è¾“
- ä½¿ç”¨å¼‚æ­¥å†…å­˜ä¼ è¾“
- åœ¨ä¼ è¾“çš„åŒæ—¶è¿›è¡Œè®¡ç®—
- æé«˜æ•´ä½“ååé‡

## æ€§èƒ½åˆ†æå·¥å…·

### 1. nvprof
```bash
nvprof --metrics all ./matrix_mul
```

### 2. Nsight Systems
- å¯è§†åŒ–æ—¶é—´çº¿
- åˆ†æCPU-GPUåŒæ­¥
- è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ

### 3. Nsight Compute
- è¯¦ç»†çš„kernelåˆ†æ
- å†…å­˜è®¿é—®æ¨¡å¼åˆ†æ
- æŒ‡ä»¤çº§æ€§èƒ½åˆ†æ

## ç¼–è¯‘å’Œè¿è¡Œ

### ç¼–è¯‘å‘½ä»¤
```bash
# åŸºç¡€ç‰ˆæœ¬
nvcc -O3 -o matrix_mul matrix_mul.cu

# é“¾æ¥cuBLAS
nvcc -O3 -lcublas -o matrix_mul_cublas matrix_mul.cu

# é“¾æ¥CUTLASS
nvcc -O3 -I/path/to/cutlass/include -o matrix_mul_cutlass matrix_mul.cu
```

### è¿è¡Œå‘½ä»¤
```bash
./matrix_mul
```

## æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•çŸ©é˜µå¤§å°
- å°çŸ©é˜µ: 512Ã—512
- ä¸­ç­‰çŸ©é˜µ: 2048Ã—2048
- å¤§çŸ©é˜µ: 8192Ã—8192

### æ€§èƒ½æŒ‡æ ‡
- GFLOPS (æ¯ç§’æµ®ç‚¹è¿ç®—æ¬¡æ•°)
- å†…å­˜å¸¦å®½åˆ©ç”¨ç‡
- è®¡ç®—æ•ˆç‡

## å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### 1. å…±äº«å†…å­˜ä¸è¶³
- å‡å°‘tileå¤§å°
- ä½¿ç”¨åŠ¨æ€å…±äº«å†…å­˜
- é‡æ–°è®¾è®¡ç®—æ³•

### 2. å¯„å­˜å™¨æº¢å‡º
- å‡å°‘æ¯ä¸ªçº¿ç¨‹çš„å˜é‡æ•°é‡
- ä½¿ç”¨å…±äº«å†…å­˜å­˜å‚¨ä¸­é—´ç»“æœ
- è°ƒæ•´çº¿ç¨‹å—å¤§å°

### 3. å†…å­˜å¸¦å®½ç“¶é¢ˆ
- ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼
- ä½¿ç”¨å‘é‡åŒ–åŠ è½½/å­˜å‚¨
- è€ƒè™‘ä½¿ç”¨çº¹ç†å†…å­˜

## ä¸‹ä¸€æ­¥
æ˜å¤©æˆ‘ä»¬å°†å­¦ä¹ å·ç§¯ç¥ç»ç½‘ç»œ(CNN)çš„å®ç°ï¼Œè¿™æ˜¯æ·±åº¦å­¦ä¹ ä¸­çš„å¦ä¸€ä¸ªé‡è¦æ“ä½œã€‚

## ç»ƒä¹ 
1. å®ç°ä¸åŒtileå¤§å°çš„ç‰ˆæœ¬ï¼Œæ¯”è¾ƒæ€§èƒ½
2. æ·»åŠ CUDAæµæ”¯æŒï¼Œå®ç°æµæ°´çº¿å¤„ç†
3. ä½¿ç”¨å‘é‡åŒ–å†…å­˜è®¿é—®ä¼˜åŒ–æ€§èƒ½
4. å®ç°ç¨€ç–çŸ©é˜µä¹˜æ³•ä¼˜åŒ–
5. å¯¹æ¯”è‡ªå®šä¹‰å®ç°ä¸cuBLAS/CUTLASSçš„æ€§èƒ½å·®å¼‚

## å‚è€ƒèµ„æ–™
- [CUDA Shared Memory](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#shared-memory)
- [CUDA Streams](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#streams)
- [Matrix Multiplication Optimization](https://developer.nvidia.com/blog/optimizing-matrix-multiplication-on-gpus/)
- [cuBLAS Documentation](https://docs.nvidia.com/cuda/cublas/)
- [CUTLASS Documentation](https://github.com/NVIDIA/cutlass)
- [NVIDIA cuBLAS Performance](https://developer.nvidia.com/cublas)
- [CUTLASS Performance Guide](https://github.com/NVIDIA/cutlass/blob/master/media/docs/performance.md)
- [Matrix Multiplication Algorithms](https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm)
- [Strassen Algorithm](https://en.wikipedia.org/wiki/Strassen_algorithm)
- [Coppersmithâ€“Winograd Algorithm](https://en.wikipedia.org/wiki/Coppersmith%E2%80%93Winograd_algorithm)
- [CUDA Performance Optimization](https://developer.nvidia.com/blog/cuda-pro-tip-increase-performance-with-vectorized-memory-access/)
- [GPU Memory Hierarchy](https://developer.nvidia.com/blog/how-access-global-memory-efficiently-in-cuda-kernels/)
- [Shared Memory Bank Conflicts](https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/)

---

## ğŸ“ ç›¸å…³æ–‡ä»¶å¿«é€Ÿé“¾æ¥
æœ¬æ•™ç¨‹åŒ…å«ä»¥ä¸‹ç›¸å…³ç¨‹åºæ–‡ä»¶ï¼Œç‚¹å‡»å³å¯æŸ¥çœ‹ï¼š

### ğŸš€ ç¤ºä¾‹ç¨‹åº
- [`matrix_mul.cu`](matrix_mul.cu) - åŸºç¡€çŸ©é˜µä¹˜æ³•å®ç°
- [`matrix_mul_optimized.cu`](matrix_mul_optimized.cu) - ä¼˜åŒ–ç‰ˆæœ¬çŸ©é˜µä¹˜æ³•
- [`matrix_mul_cublas.cu`](matrix_mul_cublas.cu) - cuBLASç‰ˆæœ¬çŸ©é˜µä¹˜æ³•
- [`matrix_mul_cutlass.cu`](matrix_mul_cutlass.cu) - CUTLASSç‰ˆæœ¬çŸ©é˜µä¹˜æ³•

### ğŸ“Š æ€§èƒ½åˆ†æå·¥å…·
- ä½¿ç”¨`nvprof`è¿›è¡Œå‘½ä»¤è¡Œæ€§èƒ½åˆ†æ
- ä½¿ç”¨Nsight Systemsè¿›è¡Œç³»ç»Ÿçº§æ€§èƒ½åˆ†æ
- ä½¿ç”¨Nsight Computeè¿›è¡Œkernelçº§æ€§èƒ½åˆ†æ

### ğŸ”§ ä¼˜åŒ–æŠ€å·§
- å…±äº«å†…å­˜ä½¿ç”¨å’Œtileä¼˜åŒ–
- CUDAæµå’Œå¼‚æ­¥æ“ä½œ
- å†…å­˜åˆå¹¶è®¿é—®ä¼˜åŒ–
- å‘é‡åŒ–å†…å­˜è®¿é—®
